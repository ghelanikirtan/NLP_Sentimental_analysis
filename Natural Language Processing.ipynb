{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622e0167",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867d9ba",
   "metadata": {},
   "source": [
    "- **Basic Steps involved in NLP with the help of Natural Language Tool Kit (nltk) as follow**:\n",
    "\n",
    "> 1. Tokenization.\n",
    "> 2. Stop Word Exclusion.\n",
    "> 3. Stemming / Lemmatization.\n",
    "> 4. POS Tagging (Part-of-Speech)\n",
    "> 5. Chunking (using Regular Expressions & RegexParser)\n",
    "> 6. NER (Named Entity Recognition) - kind of Forming groups of similar kinds `ne_chunk()`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4dc2d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00daf730",
   "metadata": {},
   "source": [
    "## NLTK Installation:\n",
    "\n",
    "`pip install nltk`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da901d44",
   "metadata": {},
   "source": [
    "## Importing Necessary Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab662cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# Natural Language Tool kit\n",
    "import nltk\n",
    "# nltk.download('package_name') - for installation of nltk packages\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c680167",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935e77f",
   "metadata": {},
   "source": [
    "## 1. TOKENIZATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f857a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91800\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "691a91be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'bought', 'these', 'for', 'my', 'husband', 'and', 'he', 'said', 'they', 'are', 'the', 'best', 'energy', 'shots', 'out', 'there', '.', 'He', 'takes', 'one', 'in', 'the', 'mornings', 'and', 'works', 'hard', 'all', 'day', '.', 'Good', 'stuff', '!']\n"
     ]
    }
   ],
   "source": [
    "testText_01 = 'I bought these for my husband and he said they are the best energy shots out there. He takes one in the mornings and works hard all day. Good stuff!'\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(testText_01)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1893cbff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c1fd5",
   "metadata": {},
   "source": [
    "## 2. Stop Word Exclusion: \n",
    "- Stop Word includes the word that do not add that much meaning to the sentence. Eg.: 'a', 'an', 'the', 'and', etc.\n",
    "- package used stopwords for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b7ee134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91800\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9a730a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous: \n",
      " ['I', 'bought', 'these', 'for', 'my', 'husband', 'and', 'he', 'said', 'they', 'are', 'the', 'best', 'energy', 'shots', 'out', 'there', '.', 'He', 'takes', 'one', 'in', 'the', 'mornings', 'and', 'works', 'hard', 'all', 'day', '.', 'Good', 'stuff', '!']\n",
      "\n",
      "Filtered: \n",
      " ['bought', 'husband', 'said', 'best', 'energy', 'shots', '.', 'takes', 'one', 'mornings', 'works', 'hard', 'day', '.', 'Good', 'stuff', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# print(stop_words)\n",
    "\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "print(\"Previous: \\n\", tokens)\n",
    "print(\"\\nFiltered: \\n\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b6251",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae4671",
   "metadata": {},
   "source": [
    "## 3. Stemming / Lemmatization:\n",
    "> **Stemming:** Used in large datasets, eg: `Caring -> Car` (can lead to incorrect meaning also).\n",
    "\n",
    "> **Lemmatization:** Converts the word to its meaningful base (Lemma), eg: `Caring -> Care` (expensive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50db1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
